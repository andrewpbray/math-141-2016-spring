---
title: "Introduction to linear regression"
output:
  html_document:
 #   css: ../lab.css
    highlight: pygments
    theme: cerulean
---


```{r load-data, include = FALSE}
library(oilabs)
library(dplyr)
library(ggplot2)
options(digits = 4)
```


1.  What type of plot would you use to display the relationship between `runs` 
    and one of the other numerical variables? Plot this relationship using the 
    variable `at_bats` as the predictor. Does the relationship look linear? If 
    you knew a team's `at_bats`, would you be comfortable using a linear model 
    to predict the number of runs?

*I'd use a scatterplot*.

```{r ex1}
qplot(x = at_bats, y = runs, data = mlb11)
```

*There appears to be a linear relationship between these variables.*

2.  Looking at your plot from the previous exercise, describe the relationship 
    between these two variables. Make sure to discuss the form, direction, and 
    strength of the relationship as well as any unusual observations.
    
*There appears to be a weak to moderate relationship between these variables 
that is positive and linear. There are no egregious unusual observations, though
a potential outlider with `at_bats` just above 5500 and `runs` above 850.*


3.  Using `plot_ss`, choose a line that does a good job of minimizing the sum of
    squares. Run the function several times. What was the smallest sum of 
    squares that you got? How does it compare to your neighbors?

*Answers will vary here.  Something like this is what we are looking for:  The smallest sum of squares that I got was 129750.5, but my neighbors were able
to get around 126,000 and around 127,000.*


4.  Fit a new model that uses `homeruns` to predict `runs`. Using the estimates 
    from the R output, write the equation of the regression line. What does the 
    slope tell us in the context of the relationship between success of a team 
    and its home runs?
    
```{r ex4}
m1 <- lm(runs ~ homeruns, data = mlb11)
summary(m1)
```

$$ \widehat{runs} = `r coef(m1)[1]` + `r coef(m1)[2]` \times homeruns $$

*The slope tells us that we'd expect a team that scores one more homerun in a
season to score about 1.8 more runs, on average.*


5.  If a team manager saw the least squares regression line and not the actual 
    data, how many runs would he or she predict for a team with 5,578 at-bats? 
    Is this an overestimate or an underestimate, and by how much? In other 
    words, what is the residual for this prediction?
    
```{r ex5}
ma <- lm(runs ~ at_bats, data = mlb11)
(y_hat <- coef(ma)[1] + coef(ma)[2] * 5578)
```

*Based on our regression model, we could predict that a team with 5,578 at bats
would score `r coef(ma)[1] + coef(ma)[2] * 5578` runs in a season. In our data set, the Philadelpha Phillies
had 5,579 at bats (so we use that as a proxy for an observed 5578 at bats runs total), so their residual indicates that they underperformed (our
model overestimated their performance).*

```{r ex5b}
y_obs <- filter(mlb11, at_bats == 5579) %>% select(runs)
y_obs - y_hat
```


```{r residuals}
qplot(x = .fitted, y = .stdresid, data = ma)
```

6.  Is there any apparent pattern in the residuals plot? What does this indicate
    about the linearity of the relationship between runs and at-bats?  

*There is no strong non-linearity in this residual plot, which indicates that 
the assumption of a linear trend between the x and the y is reasonable.*


```{r hist-res}
qplot(x = .stdresid, data = ma, geom = "histogram", binwidth = 0.5, col = I("white"))
```

or a normal probability plot of the residuals.

```{r qq-res}
qplot(sample = .stdresid, data = ma) + stat_qq() + 
  geom_abline()
```

7.  Based on the histogram and the normal probability plot, does the nearly 
    normal residuals condition appear to be met?
    
*Although there are some deviations from the line, it's reasonable to conclude
that our residuals have come from a normal distribution.*


8.  Based on the plot for the linearity condition, does the constant variability
condition appear to be met?

*It is tempting to conclude that because there are fewer small residuals
at the higher fitted values, that variance has increased. However, this could
well be explained by the fewer observations we have at those higher values. 
There are no strong indications of non-constant variance.*
    
* * *

## On Your Own

-   Choose another one of the seven traditional variables from `mlb11` besides 
    `at_bats` that you think might be a good predictor of `runs`. Produce a 
    scatterplot of the two variables and fit a linear model. At a glance, does 
    there seem to be a linear relationship?
    
*I'll choose to look at `stolen_bases`*

```{r oyo1}
qplot(x = stolen_bases, y = runs, data = mlb11)
```

*The linear relationship doesn't seem unreasonable here, but it's clear any
relationship is very weak.*


-   How does this relationship compare to the relationship between `runs` and 
    `at_bats`? Use the R$^2$ values from the two model summaries to compare. 
    Does your variable seem to predict `runs` better than `at_bats`? How can you
    tell?
    
```{r oyo2}
m2 <- lm(runs ~ stolen_bases, data = mlb11)
rsq2 <- summary(m2)$r.squared
rsqa <- summary(ma)$r.squared
```

*It's clear that `at_bats` is a far better predictor than `stolen_bases`. The 
`at_bats` model has an $R^2$ value of `r rsqa` and the `stolen_bases` model has
an $R^2$ of `r rsq2`.*

-   Now that you can summarize the linear relationship between two variables, 
    investigate the relationships between `runs` and each of the other five 
    traditional variables. Which variable best predicts `runs`? Support your 
    conclusion using the graphical and numerical methods we've discussed (for 
    the sake of conciseness, only include output for the best variable, not all 
    five).

*The strongest predictor is `bat_avg`.*

```{r oyo3}
qplot(x = bat_avg, y = runs, data = mlb11)
m3 <- lm(runs ~ bat_avg, data = mlb11)
rsq3 <- summary(m3)$r.squared
```

*The $R^2$ value for this model is `r rsq3`, which narrowly edges out some of the
other variables. The scatterplot shows that a linear trend is also sensible for
prediction.*

-   Now examine the three newer variables. These are the statistics used by the 
    author of *Moneyball* to predict a teams success. In general, are they more 
    or less effective at predicting runs that the old variables? Explain using 
    appropriate graphical and numerical evidence. Of all ten variables we've 
    analyzed, which seems to be the best predictor of `runs`? Using the limited 
    (or not so limited) information you know about these baseball statistics, 
    does your result make sense?
    
```{r oyo4}
qplot(x = new_onbase, y = runs, data = mlb11)
m4 <- lm(runs ~ new_onbase, data = mlb11)
summary(m4)$r.squared
qplot(x = new_slug, y = runs, data = mlb11)
m5 <- lm(runs ~ new_slug, data = mlb11)
summary(m5)$r.squared
qplot(x = new_ops, y = runs, data = mlb11)
m6 <- lm(runs ~ new_ops, data = mlb11)
rsq6 <- summary(m6)$r.squared
```

*The new predictors are MUCH better than the originals for predicting the number
of runs that a team will score in a season. The best predictor was `new_ops` with
an $R^2$ of `r rsq6`. I don't know much about baseball, so it's tough to assess
if this makes sense, but in general, if you can develop a metric that involves
multiple sources of information, it should be able to do a better job of 
prediction.*

-   Check the model diagnostics for the regression model with the variable you 
    decided was the best predictor for runs.
    
```{r oyo5}
qplot(x = .fitted, y = .stdresid, data = m6)
qplot(sample = .stdresid, data = m6) +
  geom_abline()
```

*The residual plot shows that our assumptions of a linear trend with constant
variance in the residuals are reasonable. The qqplot shows some small deviations
from the line, but it's still in line with what we'd expect if we had normally
distributed errors.*


<div id="license">
This is a product of OpenIntro that is released under a [Creative Commons 
Attribution-ShareAlike 3.0 Unported](http://creativecommons.org/licenses/by-sa/3.0). 
This lab was adapted for OpenIntro by Andrew Bray, Chester Ismay, and Mine &Ccedil;etinkaya-Rundel 
from a lab written by the faculty and TAs of UCLA Statistics.
</div>